# Lenny - EVE Online Market Dashboard

Lenny is a containerized web application for analyzing EVE Online market data.

## Features
- **EVE SSO Authentication**: Secure login with your EVE character.
- **AI-Powered Chat**: OpenAI integration with MCP-based tools for market analysis.
- **MCP Tools**: Model Context Protocol server with tools for market data queries:
  - List regions and search item types
  - Retrieve market orders with filtering
  - Find profitable trade routes
- **Market Dashboard**: View live market orders and trade opportunities.
- **Background Workers**: Celery tasks for fetching data from ESI.
- **SDE Database**: Pre-loaded EVE universe data (regions, systems, stations, item types).
- **Dockerized**: Easy setup with Docker Compose.

## Prerequisites
- Docker & Docker Compose
- EVE Online Developer Application (Client ID & Secret)

## Quick Start with VS Code Devcontainer (Recommended)

The fastest way to get started is using the VS Code devcontainer, which provides a complete development environment with all dependencies pre-configured.

1. **Install Prerequisites**
   - [VS Code](https://code.visualstudio.com/)
   - [Docker Desktop](https://www.docker.com/products/docker-desktop/)
   - [Remote - Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)

2. **Open in Container**
   ```bash
   git clone https://github.com/yourusername/lenny.git
   code lenny
   ```
   When VS Code opens, click "Reopen in Container" when prompted.

3. **Initialize Database**
   ```bash
   just db-init
   ```

4. **Start Development**
   - Press `F5` to launch the debugger, or
   - Run `just run-all` to start all services

See [.devcontainer/README.md](.devcontainer/README.md) for detailed documentation on debugging, available commands, and troubleshooting.

## Getting Started (Manual Setup)

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/lenny.git
   cd lenny
   ```

2. **Configure Environment**
   Create a `.env` file in the root directory:
   ```ini
   DATABASE_URL=postgresql+asyncpg://lenny:lenny@db/lenny
   CELERY_BROKER_URL=redis://redis:6379/0
   CELERY_RESULT_BACKEND=redis://redis:6379/0

   # Get these from https://developers.eveonline.com/
   EVE_CLIENT_ID=your_client_id
   EVE_CLIENT_SECRET=your_client_secret
   EVE_CALLBACK_URL=http://localhost:8000/auth/callback

   # LLM Provider Selection (openai or gemini)
   LLM_PROVIDER=openai
   LLM_MODEL=gpt-4-turbo-preview

   # OpenAI API Key (get from https://platform.openai.com/account/api-keys)
   OPENAI_API_KEY=your_openai_api_key

   # Google Gemini API Key (get from https://aistudio.google.com/app/apikey)
   GEMINI_API_KEY=your_gemini_api_key

   SECRET_KEY=your_secret_key # Use a strong random key
   ```

   > **Note:** You only need to configure the API key for your chosen `LLM_PROVIDER`.
   > For example, if using Gemini, only `GEMINI_API_KEY` is required.

3. **Run with Docker Compose**
   ```bash
   docker-compose up --build
   ```

## Database Schema & Alembic

Migrations are autogenerated from SQLAlchemy models; no raw SQL.
Indexes are defined in models via `index=True` or `__table_args__ = (Index(...),)`.
Autogenerate revisions inside the backend container to keep environments consistent.

### Fresh Dev Instance (Option A)

Use when you want a clean database and migration history.

**Step 1: Reset the environment**
```zsh
docker compose down -v
docker compose up --build -d
docker compose ps
# Wait for all services to start
docker compose exec backend alembic upgrade head
```

At this point you have a fresh instance with no data.

**Step 2: Initialize the database with SDE data and fetch market orders**

```zsh
docker compose exec backend python init_database.py
```

This will:
- Load SDE data (regions, systems, stations, item types)
- Queue Celery tasks to fetch market orders for all regions
- Queue Celery tasks to fetch market history for all regions

**Step 3: Monitor the data fetching**
```zsh
# Watch worker logs to see data fetching progress
docker compose logs worker --follow
```

**Troubleshooting:** If tables were already created by startup code and `alembic upgrade` fails with duplicate table errors, stamp the DB to the latest initial revision:

```zsh
docker compose exec backend alembic stamp head
```

The application uses an abstracted LLM provider interface, allowing you to easily swap between different AI providers:

### Finding the latest revision ID

```zsh


### Normal Workflow

When models change (including new indexes):
```

### Normal Workflow

When models change (including new indexes):
```zsh

```zsh
- **OpenAI** (default): Uses GPT-4 Turbo or other OpenAI models
- **Gemini**: Google's Gemini API for powerful AI capabilities
- **Custom**: Extend `llm_providers.base.LLMProvider` to add more providers
```

### Notes

Keep migrations database-agnostic: use Alembic ops (`op.create_table`, `op.create_index`, etc.).
Do not hand-write SQL migrations; rely on autogenerate and adjust Python ops if needed.
If Alembic reports "Target database is not up to date", ensure you ran `upgrade head` or `stamp` appropriately.

To switch providers, update `.env`:
```ini

### Notes
 Do not hand-write SQL migrations; rely on autogenerate and adjust Python ops if needed.
 If Alembic reports "Target database is not up to date", ensure you ran `upgrade head` or `stamp` appropriately.
```


The application is instrumented with OpenTelemetry for distributed tracing and observability.

- **Aspire Dashboard**: A local dashboard is included to view traces, metrics, and logs.
  - URL: [http://localhost:18888](http://localhost:18888)
  - No configuration required; it runs automatically with Docker Compose.
- **Instrumentation**:
  - **Backend (FastAPI)**: Automatically traces all incoming HTTP requests and DB queries.
  - **Worker (Celery)**: Traces background tasks and their execution.

### Database Migrations
We use Alembic for database migrations.

    ```bash
    source .venv/bin/activate
    ```

2.  **Run Migrations**:
    Navigate to the `backend` directory and run alembic commands.

    **Create a Migration**:
    ```bash
    cd backend
    DATABASE_URL=postgresql+asyncpg://lenny:lenny@localhost:5432/lenny ../.venv/bin/alembic revision --autogenerate -m "Description"
    ```

    **Apply Migrations**:
    ```bash
    cd backend
    DATABASE_URL=postgresql+asyncpg://lenny:lenny@localhost:5432/lenny ../.venv/bin/alembic upgrade head
    ```

## VS Code Development Setup

1. **Open the Project**
   Open the `lenny` folder in VS Code.

2. **Recommended Extensions**
   - **Python** (Microsoft)
   - **Docker** (Microsoft)
   - **ESLint** (Microsoft)
   - **Prettier** (Prettier)

3. **Python Environment (Backend)**
   This project uses PDM. To configure VS Code to use the PDM virtual environment:
   1. Run `pdm install` in the terminal to create the virtual environment.
   2. Open the Command Palette (`Cmd+Shift+P`) and select **Python: Select Interpreter**.
   3. Choose the interpreter inside the `.venv` folder (e.g., `.venv/bin/python`).

4. **Frontend Setup**
   1. Navigate to the frontend directory: `cd frontend`
   2. Install dependencies: `npm install`
   3. Start the dev server: `npm run dev`

5. **Running Services**
   You can run the full stack using Docker Compose, or run services individually for debugging.
   - **Docker Compose**: Right-click `docker-compose.yml` and select **Compose Up**.

## License
MIT
